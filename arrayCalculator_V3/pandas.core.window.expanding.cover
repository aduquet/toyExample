    1: from __future__ import annotations
       
    1: from textwrap import dedent
    1: from typing import (
           TYPE_CHECKING,
           Any,
           Callable,
       )
       
    1: from pandas._typing import (
           Axis,
           WindowingRankType,
       )
       
    1: if TYPE_CHECKING:
           from pandas import DataFrame, Series
           from pandas.core.generic import NDFrame
       
    1: from pandas.compat.numpy import function as nv
    1: from pandas.util._decorators import doc
       
    1: from pandas.core.indexers.objects import (
           BaseIndexer,
           ExpandingIndexer,
           GroupbyIndexer,
       )
    1: from pandas.core.window.doc import (
           _shared_docs,
           args_compat,
           create_section_header,
           kwargs_compat,
           numba_notes,
           template_header,
           template_returns,
           template_see_also,
           window_agg_numba_parameters,
           window_apply_parameters,
       )
    1: from pandas.core.window.rolling import (
           BaseWindowGroupby,
           RollingAndExpandingMixin,
       )
       
       
    2: class Expanding(RollingAndExpandingMixin):
    1:     """
           Provide expanding window calculations.
       
           Parameters
           ----------
           min_periods : int, default 1
               Minimum number of observations in window required to have a value;
               otherwise, result is ``np.nan``.
       
           center : bool, default False
               If False, set the window labels as the right edge of the window index.
       
               If True, set the window labels as the center of the window index.
       
               .. deprecated:: 1.1.0
       
           axis : int or str, default 0
               If ``0`` or ``'index'``, roll across the rows.
       
               If ``1`` or ``'columns'``, roll across the columns.
       
           method : str {'single', 'table'}, default 'single'
               Execute the rolling operation per single column or row (``'single'``)
               or over the entire object (``'table'``).
       
               This argument is only implemented when specifying ``engine='numba'``
               in the method call.
       
               .. versionadded:: 1.3.0
       
           Returns
           -------
           ``Expanding`` subclass
       
           See Also
           --------
           rolling : Provides rolling window calculations.
           ewm : Provides exponential weighted functions.
       
           Notes
           -----
           See :ref:`Windowing Operations <window.expanding>` for further usage details
           and examples.
       
           Examples
           --------
           >>> df = pd.DataFrame({"B": [0, 1, 2, np.nan, 4]})
           >>> df
                B
           0  0.0
           1  1.0
           2  2.0
           3  NaN
           4  4.0
       
           **min_periods**
       
           Expanding sum with 1 vs 3 observations needed to calculate a value.
       
           >>> df.expanding(1).sum()
                B
           0  0.0
           1  1.0
           2  3.0
           3  3.0
           4  7.0
           >>> df.expanding(3).sum()
                B
           0  NaN
           1  NaN
           2  3.0
           3  3.0
           4  7.0
           """
       
    1:     _attributes: list[str] = ["min_periods", "center", "axis", "method"]
       
    1:     def __init__(
               self,
               obj: NDFrame,
               min_periods: int = 1,
               center=None,
               axis: Axis = 0,
               method: str = "single",
               selection=None,
           ):
               super().__init__(
                   obj=obj,
                   min_periods=min_periods,
                   center=center,
                   axis=axis,
                   method=method,
                   selection=selection,
               )
       
    1:     def _get_window_indexer(self) -> BaseIndexer:
               """
               Return an indexer class that will compute the window start and end bounds
               """
               return ExpandingIndexer()
       
    2:     @doc(
    1:         _shared_docs["aggregate"],
    2:         see_also=dedent(
    1:             """
               See Also
               --------
               pandas.DataFrame.aggregate : Similar DataFrame method.
               pandas.Series.aggregate : Similar Series method.
               """
               ),
    2:         examples=dedent(
    1:             """
               Examples
               --------
               >>> df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
               >>> df
                  A  B  C
               0  1  4  7
               1  2  5  8
               2  3  6  9
       
               >>> df.ewm(alpha=0.5).mean()
                         A         B         C
               0  1.000000  4.000000  7.000000
               1  1.666667  4.666667  7.666667
               2  2.428571  5.428571  8.428571
               """
               ),
    1:         klass="Series/Dataframe",
    1:         axis="",
           )
    1:     def aggregate(self, func, *args, **kwargs):
               return super().aggregate(func, *args, **kwargs)
       
    1:     agg = aggregate
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="count of non NaN observations",
    1:         agg_method="count",
           )
    1:     def count(self):
               return super().count()
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         window_apply_parameters,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="custom aggregation function",
    1:         agg_method="apply",
           )
    1:     def apply(
               self,
               func: Callable[..., Any],
               raw: bool = False,
               engine: str | None = None,
               engine_kwargs: dict[str, bool] | None = None,
               args: tuple[Any, ...] | None = None,
               kwargs: dict[str, Any] | None = None,
           ):
               return super().apply(
                   func,
                   raw=raw,
                   engine=engine,
                   engine_kwargs=engine_kwargs,
                   args=args,
                   kwargs=kwargs,
               )
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         args_compat,
    1:         window_agg_numba_parameters(),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         numba_notes[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="sum",
    1:         agg_method="sum",
           )
    1:     def sum(
               self,
               *args,
    1:         engine: str | None = None,
    1:         engine_kwargs: dict[str, bool] | None = None,
               **kwargs,
           ):
               nv.validate_expanding_func("sum", args, kwargs)
               return super().sum(*args, engine=engine, engine_kwargs=engine_kwargs, **kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         args_compat,
    1:         window_agg_numba_parameters(),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         numba_notes[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="maximum",
    1:         agg_method="max",
           )
    1:     def max(
               self,
               *args,
    1:         engine: str | None = None,
    1:         engine_kwargs: dict[str, bool] | None = None,
               **kwargs,
           ):
               nv.validate_expanding_func("max", args, kwargs)
               return super().max(*args, engine=engine, engine_kwargs=engine_kwargs, **kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         args_compat,
    1:         window_agg_numba_parameters(),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         numba_notes[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="minimum",
    1:         agg_method="min",
           )
    1:     def min(
               self,
               *args,
    1:         engine: str | None = None,
    1:         engine_kwargs: dict[str, bool] | None = None,
               **kwargs,
           ):
               nv.validate_expanding_func("min", args, kwargs)
               return super().min(*args, engine=engine, engine_kwargs=engine_kwargs, **kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         args_compat,
    1:         window_agg_numba_parameters(),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         numba_notes[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="mean",
    1:         agg_method="mean",
           )
    1:     def mean(
               self,
               *args,
    1:         engine: str | None = None,
    1:         engine_kwargs: dict[str, bool] | None = None,
               **kwargs,
           ):
               nv.validate_expanding_func("mean", args, kwargs)
               return super().mean(*args, engine=engine, engine_kwargs=engine_kwargs, **kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         window_agg_numba_parameters(),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         numba_notes[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="median",
    1:         agg_method="median",
           )
    1:     def median(
               self,
               engine: str | None = None,
               engine_kwargs: dict[str, bool] | None = None,
               **kwargs,
           ):
               return super().median(engine=engine, engine_kwargs=engine_kwargs, **kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    3:         dedent(
    1:             """
               ddof : int, default 1
                   Delta Degrees of Freedom.  The divisor used in calculations
                   is ``N - ddof``, where ``N`` represents the number of elements.\n
               """
    1:         ).replace("\n", "", 1),
    1:         args_compat,
    1:         window_agg_numba_parameters("1.4"),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         "numpy.std : Equivalent method for NumPy array.\n",
    1:         template_see_also,
    1:         create_section_header("Notes"),
    3:         dedent(
    1:             """
               The default ``ddof`` of 1 used in :meth:`Series.std` is different
               than the default ``ddof`` of 0 in :func:`numpy.std`.
       
               A minimum of one period is required for the rolling calculation.\n
               """
    1:         ).replace("\n", "", 1),
    1:         create_section_header("Examples"),
    3:         dedent(
    1:             """
               >>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
       
               >>> s.expanding(3).std()
               0         NaN
               1         NaN
               2    0.577350
               3    0.957427
               4    0.894427
               5    0.836660
               6    0.786796
               dtype: float64
               """
    1:         ).replace("\n", "", 1),
    1:         window_method="expanding",
    1:         aggregation_description="standard deviation",
    1:         agg_method="std",
           )
    2:     def std(
               self,
               ddof: int = 1,
               *args,
    1:         engine: str | None = None,
    1:         engine_kwargs: dict[str, bool] | None = None,
               **kwargs,
           ):
               nv.validate_expanding_func("std", args, kwargs)
               return super().std(
                   ddof=ddof, engine=engine, engine_kwargs=engine_kwargs, **kwargs
               )
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    3:         dedent(
    1:             """
               ddof : int, default 1
                   Delta Degrees of Freedom.  The divisor used in calculations
                   is ``N - ddof``, where ``N`` represents the number of elements.\n
               """
    1:         ).replace("\n", "", 1),
    1:         args_compat,
    1:         window_agg_numba_parameters("1.4"),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         "numpy.var : Equivalent method for NumPy array.\n",
    1:         template_see_also,
    1:         create_section_header("Notes"),
    3:         dedent(
    1:             """
               The default ``ddof`` of 1 used in :meth:`Series.var` is different
               than the default ``ddof`` of 0 in :func:`numpy.var`.
       
               A minimum of one period is required for the rolling calculation.\n
               """
    1:         ).replace("\n", "", 1),
    1:         create_section_header("Examples"),
    3:         dedent(
    1:             """
               >>> s = pd.Series([5, 5, 6, 7, 5, 5, 5])
       
               >>> s.expanding(3).var()
               0         NaN
               1         NaN
               2    0.333333
               3    0.916667
               4    0.800000
               5    0.700000
               6    0.619048
               dtype: float64
               """
    1:         ).replace("\n", "", 1),
    1:         window_method="expanding",
    1:         aggregation_description="variance",
    1:         agg_method="var",
           )
    2:     def var(
               self,
               ddof: int = 1,
               *args,
    1:         engine: str | None = None,
    1:         engine_kwargs: dict[str, bool] | None = None,
               **kwargs,
           ):
               nv.validate_expanding_func("var", args, kwargs)
               return super().var(
                   ddof=ddof, engine=engine, engine_kwargs=engine_kwargs, **kwargs
               )
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    3:         dedent(
    1:             """
               ddof : int, default 1
                   Delta Degrees of Freedom.  The divisor used in calculations
                   is ``N - ddof``, where ``N`` represents the number of elements.\n
               """
    1:         ).replace("\n", "", 1),
    1:         args_compat,
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         "A minimum of one period is required for the calculation.\n\n",
    1:         create_section_header("Examples"),
    3:         dedent(
    1:             """
               >>> s = pd.Series([0, 1, 2, 3])
       
               >>> s.expanding().sem()
               0         NaN
               1    0.707107
               2    0.707107
               3    0.745356
               dtype: float64
               """
    1:         ).replace("\n", "", 1),
    1:         window_method="expanding",
    1:         aggregation_description="standard error of mean",
    1:         agg_method="sem",
           )
    1:     def sem(self, ddof: int = 1, *args, **kwargs):
               return super().sem(ddof=ddof, **kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         "scipy.stats.skew : Third moment of a probability density.\n",
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         "A minimum of three periods is required for the rolling calculation.\n",
    1:         window_method="expanding",
    1:         aggregation_description="unbiased skewness",
    1:         agg_method="skew",
           )
    1:     def skew(self, **kwargs):
               return super().skew(**kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         "scipy.stats.kurtosis : Reference SciPy method.\n",
    1:         template_see_also,
    1:         create_section_header("Notes"),
    1:         "A minimum of four periods is required for the calculation.\n\n",
    1:         create_section_header("Examples"),
    3:         dedent(
    1:             """
               The example below will show a rolling calculation with a window size of
               four matching the equivalent function call using `scipy.stats`.
       
               >>> arr = [1, 2, 3, 4, 999]
               >>> import scipy.stats
               >>> print(f"{{scipy.stats.kurtosis(arr[:-1], bias=False):.6f}}")
               -1.200000
               >>> print(f"{{scipy.stats.kurtosis(arr, bias=False):.6f}}")
               4.999874
               >>> s = pd.Series(arr)
               >>> s.expanding(4).kurt()
               0         NaN
               1         NaN
               2         NaN
               3   -1.200000
               4    4.999874
               dtype: float64
               """
    1:         ).replace("\n", "", 1),
    1:         window_method="expanding",
    1:         aggregation_description="Fisher's definition of kurtosis without bias",
    1:         agg_method="kurt",
           )
    1:     def kurt(self, **kwargs):
               return super().kurt(**kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    3:         dedent(
    1:             """
               quantile : float
                   Quantile to compute. 0 <= quantile <= 1.
               interpolation : {{'linear', 'lower', 'higher', 'midpoint', 'nearest'}}
                   This optional parameter specifies the interpolation method to use,
                   when the desired quantile lies between two data points `i` and `j`:
       
                       * linear: `i + (j - i) * fraction`, where `fraction` is the
                         fractional part of the index surrounded by `i` and `j`.
                       * lower: `i`.
                       * higher: `j`.
                       * nearest: `i` or `j` whichever is nearest.
                       * midpoint: (`i` + `j`) / 2.
               """
    1:         ).replace("\n", "", 1),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="quantile",
    1:         agg_method="quantile",
           )
    1:     def quantile(
               self,
               quantile: float,
               interpolation: str = "linear",
               **kwargs,
           ):
               return super().quantile(
                   quantile=quantile,
                   interpolation=interpolation,
                   **kwargs,
               )
       
    2:     @doc(
    1:         template_header,
    1:         ".. versionadded:: 1.4.0 \n\n",
    1:         create_section_header("Parameters"),
    3:         dedent(
    1:             """
               method : {{'average', 'min', 'max'}}, default 'average'
                   How to rank the group of records that have the same value (i.e. ties):
       
                   * average: average rank of the group
                   * min: lowest rank in the group
                   * max: highest rank in the group
       
               ascending : bool, default True
                   Whether or not the elements should be ranked in ascending order.
               pct : bool, default False
                   Whether or not to display the returned rankings in percentile
                   form.
               """
    1:         ).replace("\n", "", 1),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also,
    1:         create_section_header("Examples"),
    3:         dedent(
    1:             """
               >>> s = pd.Series([1, 4, 2, 3, 5, 3])
               >>> s.expanding().rank()
               0    1.0
               1    2.0
               2    2.0
               3    3.0
               4    5.0
               5    3.5
               dtype: float64
       
               >>> s.expanding().rank(method="max")
               0    1.0
               1    2.0
               2    2.0
               3    3.0
               4    5.0
               5    4.0
               dtype: float64
       
               >>> s.expanding().rank(method="min")
               0    1.0
               1    2.0
               2    2.0
               3    3.0
               4    5.0
               5    3.0
               dtype: float64
               """
    1:         ).replace("\n", "", 1),
    1:         window_method="expanding",
    1:         aggregation_description="rank",
    1:         agg_method="rank",
           )
    1:     def rank(
               self,
               method: WindowingRankType = "average",
               ascending: bool = True,
               pct: bool = False,
               **kwargs,
           ):
               return super().rank(
                   method=method,
                   ascending=ascending,
                   pct=pct,
                   **kwargs,
               )
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    3:         dedent(
    1:             """
               other : Series or DataFrame, optional
                   If not supplied then will default to self and produce pairwise
                   output.
               pairwise : bool, default None
                   If False then only matching columns between self and other will be
                   used and the output will be a DataFrame.
                   If True then all pairwise combinations will be calculated and the
                   output will be a MultiIndexed DataFrame in the case of DataFrame
                   inputs. In the case of missing elements, only complete pairwise
                   observations will be used.
               ddof : int, default 1
                   Delta Degrees of Freedom.  The divisor used in calculations
                   is ``N - ddof``, where ``N`` represents the number of elements.
               """
    1:         ).replace("\n", "", 1),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    1:         template_see_also[:-1],
    1:         window_method="expanding",
    1:         aggregation_description="sample covariance",
    1:         agg_method="cov",
           )
    1:     def cov(
               self,
               other: DataFrame | Series | None = None,
               pairwise: bool | None = None,
               ddof: int = 1,
               **kwargs,
           ):
               return super().cov(other=other, pairwise=pairwise, ddof=ddof, **kwargs)
       
    2:     @doc(
    1:         template_header,
    1:         create_section_header("Parameters"),
    3:         dedent(
    1:             """
               other : Series or DataFrame, optional
                   If not supplied then will default to self and produce pairwise
                   output.
               pairwise : bool, default None
                   If False then only matching columns between self and other will be
                   used and the output will be a DataFrame.
                   If True then all pairwise combinations will be calculated and the
                   output will be a MultiIndexed DataFrame in the case of DataFrame
                   inputs. In the case of missing elements, only complete pairwise
                   observations will be used.
               """
    1:         ).replace("\n", "", 1),
    1:         kwargs_compat,
    1:         create_section_header("Returns"),
    1:         template_returns,
    1:         create_section_header("See Also"),
    3:         dedent(
    1:             """
               cov : Similar method to calculate covariance.
               numpy.corrcoef : NumPy Pearson's correlation calculation.
               """
    1:         ).replace("\n", "", 1),
    1:         template_see_also,
    1:         create_section_header("Notes"),
    3:         dedent(
    1:             """
               This function uses Pearson's definition of correlation
               (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient).
       
               When `other` is not specified, the output will be self correlation (e.g.
               all 1's), except for :class:`~pandas.DataFrame` inputs with `pairwise`
               set to `True`.
       
               Function will return ``NaN`` for correlations of equal valued sequences;
               this is the result of a 0/0 division error.
       
               When `pairwise` is set to `False`, only matching columns between `self` and
               `other` will be used.
       
               When `pairwise` is set to `True`, the output will be a MultiIndex DataFrame
               with the original index on the first level, and the `other` DataFrame
               columns on the second level.
       
               In the case of missing elements, only complete pairwise observations
               will be used.
               """
    1:         ).replace("\n", "", 1),
    1:         window_method="expanding",
    1:         aggregation_description="correlation",
    1:         agg_method="corr",
           )
    1:     def corr(
               self,
               other: DataFrame | Series | None = None,
               pairwise: bool | None = None,
               ddof: int = 1,
               **kwargs,
           ):
               return super().corr(other=other, pairwise=pairwise, ddof=ddof, **kwargs)
       
       
    2: class ExpandingGroupby(BaseWindowGroupby, Expanding):
    1:     """
           Provide a expanding groupby implementation.
           """
       
    1:     _attributes = Expanding._attributes + BaseWindowGroupby._attributes
       
    1:     def _get_window_indexer(self) -> GroupbyIndexer:
               """
               Return an indexer class that will compute the window start and end bounds
       
               Returns
               -------
               GroupbyIndexer
               """
               window_indexer = GroupbyIndexer(
                   groupby_indices=self._grouper.indices,
                   window_indexer=ExpandingIndexer,
               )
               return window_indexer
